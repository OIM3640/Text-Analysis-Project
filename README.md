# Text-Analysis-Project
 
Please read the [instructions](instructions.md).
extra code line used w explanations from gpt:https://www.nltk.org/data.html
https://chat.openai.com/share/d0c052d3-525f-46ff-8a44-ea2ceb35ad55
https://chat.openai.com/share/9143bb30-37a1-4c06-a5cb-d8a6c39e943b


I saw that the reviews from de imdb api and realized they were so long and I did not want to use a common words in each review function instead I wanted a logical summary function and i checked internet about it if any packages exist. I ve found out the code line but I did not understand it so I utilized gpt to explain me everything line by line. I utilized sentimenting as well. I utilized nltk for these
My project consists of 4 main functions where 2 of them are nested so 3 different functions that serve the user. Firstly I needed to import all of the packages, then I made the instances for the api. After it, I made a function for text summirizer, where the function uses corpus and tokenizers, to get text as an input, get the stopwords from nltk, tokenizes into a text without stop words, and makes a frequency table. The function calculates a score with the frequency of the words that are tokenized, later the function makes a summary of the input text for those with a score of >=1.2 of average and gives out a summary. next function is for getting all of the reviews from the api of imdb, and then using the summirizer crated before to summirize each review in a loop.
The other function is for counting the number of predifined list of -good or simmilar to good words in each review and summirizing it to the user in numerical values of hom many times the good connotation words are seen. The last function serves to sentiment each review, using the SentimentIntensityAnalyzer, the function takes each review in a loop, and returns the sentiment type, neutral/negative/positive and total count of the sentiment types. 
For the result, one interesting thing that I found was tokenizing and using the summirizer. I utilized and changed a code that i found online that rates every word and creates a smaller summary for each reviews. Also, with the NLTK pacages I was able use a sentiment function with the help of the code provided in instructions and also reddit about nltk. 
Also, I utilized lists and searched for a list of words in a given text from api, I extracted from. and I summirzed the number of times these list of words are mentioned in all of the movies in the specified movie name. 
What went well was that the data gathering from the api was easy and the loops used in each function were simmilar to each other so i just adjusted them a bit. Also, utulizing a code from the internet and making it applicaple for my case was not so hard to do. I think what the code could further develop is by just geting the input and the red line barriers for negative connotations from each comment, it could give a percentage score about the move if its worth watching or not. Yes, I had a good testing plan.
GPT and reddit helped me a lot in my coding process especially for sentimenting and the summary maker. GPT really helped me build up the logic flows of the function and also made good reccomendations, I will definatelly use the packages I learned in this project