### Text-Analysis-Project

# Project Overview 
For this specific Python project, I decided to use one of the data sources suggested by the project instructions, which is Wikipedia. I decided to explore about specifically “James Harden,” “2017–18 Houston Rockets season,” and “2018 Western Conference Finals.” The reason why I am choose this is because I have been a basketball fan for over 10 years and I have also played varsity basketball in my highschool team. My favorite player inside of the National Basketball League is James Harden and he has been someone that I really look up to. Something that has been in my mind for a long time is how James Harden despite having a lot of achievements like MVP and Allstar, people would not put him on par as other greatest of all time player because he has never won a championship team. The closest he has ever gone in the playoffs is the 2018 Western Conference Finals and for me everytime I have flashbacks watching the playoffs in 2018 I get very sad because it was a perfect oppurtunity for James Harden to prove himself to be one of the best playser in the League. Without the championship, also James Harden is considered a great player during regular season, he will be labeled as a playoff choker who never really proved himself when things really mattered.

For this Python project, I want to download the articles on Wikipedia using the mediawiki python package and clean the text by removing citation brackets in order for it to be easier processed. From my machine learning class QTM3635 we learned a lot of data cleaning and tokenization, so I want to perform a tokenization process with a stopword list simialr to my QTM class. However, rather than having a URL for the stoplist, I have used Chatgpt to create a tiny stoplist for my project. I am also performing bag of words representation, comparing which words are the most frequent within the season and which words are most frequent within the playoffs. From this project, I really want to see how different do people think James Harden performs during the playoffs compared to the regular season. I will do so by changing the raw data from the web text into structured data.

# Implementation
For implementation, I decided to have two python files, one on downloading the information from wikipedia and the other on text analysis. For the first data acquisition code, I used python to do some data acquisition and cleaning by the recommended mediawiki feature within python. I fetched information from three wikipedia pages regarding James Harden and the 2017-2018 Houston Rockets Season. I was able to strip all of the citation markers and was able to store the data within a Python dictionary. Additionally, Chatgpt recommended that I used the JSONL feature where it will have one JKSOn object per line consisting of the title and the content. Secondly, I had code for analysis, which tokenize the data and uses bag of words representation. The stop list I used allows me to identify actual words that are useful for the experiment and get rid of random words such as "that, and, of". I coded the data so that it will print top 15 words per document, compare the season page and the WCF page to find words that are common in one but not the other , compute cosine similarity for the three document pairs, and scan for capitalized tokens to get likely proper names. 

At the same time, I have gave my code for the two documents and asked Chatgpt to give me more detailed and complex code for better graphs and models and it was able to produce very interesting results, where I added a page called "part 3 chatgpt". I used a detailed prompt to chatgpt to do more detailed data cleaning and tokenization. I was able to explore the feature of "matplotlib" where it adds a lot of visualization layer to my code. It also added "ensure_fig_dir()" to make a figure folder within the respository and use "slugif" to turn titles into file names. All of those features are beyond my knowledge of python but I appreciate that the professor allows us to use Chatgpt to help us because it can really teach me how I can improve my code and introduce me to very useful and interesting code and features that I have not know before. With the guidance of chatgpt, I was able to create a lot of visual graphs, plos for top words used per document, plot for season versus the western eastern conference, plot for cosine heatmap, and plot for proper names of all. 


# Results 
![alt text](image.png)

# Reflection